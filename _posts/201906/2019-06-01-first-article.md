---
layout: post
title:  "如何维护爬虫系统的散列表"
categories: jekyll update
---
背景：在爬虫系统中，需要一个散列表去记录哪些url已经被抓取，这在一台服务器上并非难事。但是如果同时有上千台服务器一起下载网页，维护一张同意的散列表就不那么简单了：首先，这张散列表会大到一台服务器存储不下。其次，由于每个下载服务器在开始下载和完成下载后都要访问和维护这张表，以免不同的服务器做重复的工作，那么和存储散列表的服务器的通信就成了这个爬虫系统的瓶颈。

解决方案要包含以下两个方面：首先明确每台下载服务器的分工，也就是说在调度时一看到某个URL就知道要交给哪台服务器去下载，一面很多服务器都要重复判断某个URL是否需要下载。然后，在明确分工的基础上，判断URL是否下载就可以批处理了，比如每次向散列表（一组独立的服务器）发送一大批查询，或者每次更新一大批撒列表的内容。这样通信的次数就大大减少了。